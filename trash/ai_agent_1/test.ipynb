{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eba8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Union, TypedDict\n",
    "import getpass\n",
    "\n",
    "# LangChain / LangGraph Imports\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# --- API KEY SETUP ---\n",
    "# If you haven't set this in your environment variables, uncomment below:\n",
    "# os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter OpenAI API Key: \")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29e327e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTIONS ---\n",
    "\n",
    "def find_next_missing_field(data: Dict, path: List[str] = []) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Recursively searches for the first field where 'requis' is True\n",
    "    and 'valeur' is empty/None.\n",
    "    \"\"\"\n",
    "    for key, value in data.items():\n",
    "        current_path = path + [key]\n",
    "\n",
    "        if isinstance(value, dict) and \"valeur\" in value and \"requis\" in value:\n",
    "            if value.get(\"type\") == \"fixe\":\n",
    "                continue\n",
    "            \n",
    "            # Check if value is empty\n",
    "            is_empty = value[\"valeur\"] in [None, \"\", []]\n",
    "            if value[\"requis\"] and is_empty:\n",
    "                return {\"path\": current_path, \"schema\": value, \"key\": key}\n",
    "\n",
    "        elif isinstance(value, dict):\n",
    "            result = find_next_missing_field(value, current_path)\n",
    "            if result:\n",
    "                return result\n",
    "\n",
    "        elif isinstance(value, list):\n",
    "            for idx, item in enumerate(value):\n",
    "                if isinstance(item, dict):\n",
    "                    result = find_next_missing_field(item, current_path + [str(idx)])\n",
    "                    if result:\n",
    "                        return result\n",
    "    return None\n",
    "\n",
    "def update_json_value(data: Dict, path: List[str], new_value: Any):\n",
    "    \"\"\"Updates the JSON structure at the specific path in-place.\"\"\"\n",
    "    ref = data\n",
    "    for key in path[:-1]:\n",
    "        if key.isdigit() and isinstance(ref, list):\n",
    "            ref = ref[int(key)]\n",
    "        else:\n",
    "            ref = ref[key]\n",
    "\n",
    "    last_key = path[-1]\n",
    "    if last_key.isdigit() and isinstance(ref, list):\n",
    "        ref[int(last_key)][\"valeur\"] = new_value\n",
    "    else:\n",
    "        ref[last_key][\"valeur\"] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a058b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- STATE DEFINITION ---\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    contract_data: Dict\n",
    "    current_field_info: Optional[Dict]\n",
    "    completed: bool\n",
    "\n",
    "# --- NODES ---\n",
    "\n",
    "def determine_progress(state: AgentState):\n",
    "    data = state.get(\"contract_data\")\n",
    "    next_field = find_next_missing_field(data)\n",
    "\n",
    "    if not next_field:\n",
    "        return {\"completed\": True, \"current_field_info\": None}\n",
    "\n",
    "    return {\"completed\": False, \"current_field_info\": next_field}\n",
    "\n",
    "def generate_question(state: AgentState):\n",
    "    field_info = state[\"current_field_info\"]\n",
    "    path_str = \" > \".join(field_info[\"path\"])\n",
    "    field_type = field_info[\"schema\"].get(\"type\")\n",
    "    options = field_info[\"schema\"].get(\"options\", [])\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a helpful French real estate legal assistant filling out a rental contract.\n",
    "    Your goal is to ask the user for specific information to fill the JSON field: \"{path_str}\".\n",
    "    \n",
    "    Field Type: {field_type}\n",
    "    Options: {options}\n",
    "    \n",
    "    Phrase your question naturally in French.\n",
    "    \"\"\"\n",
    "    \n",
    "    # specific instruction to handle the very first turn if messages are empty\n",
    "    msg = llm.invoke([SystemMessage(content=system_prompt)])\n",
    "    return {\"messages\": [msg]}\n",
    "\n",
    "# Re-run this cell to update the logic\n",
    "def process_answer(state: AgentState):\n",
    "    messages = state[\"messages\"]\n",
    "    last_user_msg = messages[-1]\n",
    "    field_info = state[\"current_field_info\"]\n",
    "\n",
    "    if not field_info:\n",
    "        return {}\n",
    "\n",
    "    # --- FIX 1: Use Union instead of Any ---\n",
    "    # OpenAI needs concrete types. We allow the most common ones.\n",
    "    class Extraction(BaseModel):\n",
    "        value: Union[str, int, float, bool] = Field(\n",
    "            description=\"The extracted value. Use correct type (bool for booleen, int/float for nombre).\"\n",
    "        )\n",
    "\n",
    "    field_type = field_info[\"schema\"].get(\"type\")\n",
    "    options = field_info[\"schema\"].get(\"options\", [])\n",
    "\n",
    "    extraction_prompt = f\"\"\"\n",
    "    Extract the value for field \"{field_info['key']}\" from: \"{last_user_msg.content}\"\n",
    "    \n",
    "    Target Type: {field_type}\n",
    "    Allowed Options: {options}\n",
    "    \n",
    "    - If type is 'booleen', return a boolean.\n",
    "    - If type is 'nombre', return a number.\n",
    "    - If type is 'date', return a string YYYY-MM-DD.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- FIX 2: Specify method=\"function_calling\" ---\n",
    "    # This creates a more compatible schema for Unions and optional fields\n",
    "    structured_llm = llm.with_structured_output(Extraction, method=\"function_calling\")\n",
    "    \n",
    "    result = structured_llm.invoke(extraction_prompt)\n",
    "\n",
    "    # Update the main JSON data\n",
    "    current_data = state[\"contract_data\"]\n",
    "    update_json_value(current_data, field_info[\"path\"], result.value)\n",
    "\n",
    "    return {\"contract_data\": current_data}\n",
    "def save_contract(state: AgentState):\n",
    "    # Saving to a local file in the notebook directory\n",
    "    with open(\"contrat_finalise.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(state[\"contract_data\"], f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [AIMessage(content=\"Termin√© ! Le contrat a √©t√© sauvegard√© dans 'contrat_finalise.json'.\")]\n",
    "    }\n",
    "\n",
    "# --- GRAPH CONSTRUCTION ---\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"determine_progress\", determine_progress)\n",
    "workflow.add_node(\"generate_question\", generate_question)\n",
    "workflow.add_node(\"process_answer\", process_answer)\n",
    "workflow.add_node(\"save_contract\", save_contract)\n",
    "\n",
    "def route_start(state: AgentState):\n",
    "    # If last message is from Human, we need to process it\n",
    "    if state[\"messages\"] and isinstance(state[\"messages\"][-1], HumanMessage):\n",
    "        return \"process_answer\"\n",
    "    return \"determine_progress\"\n",
    "\n",
    "def route_after_progress(state: AgentState):\n",
    "    if state[\"completed\"]:\n",
    "        return \"save_contract\"\n",
    "    return \"generate_question\"\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_start,\n",
    "    {\"process_answer\": \"process_answer\", \"determine_progress\": \"determine_progress\"},\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"process_answer\", \"determine_progress\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"determine_progress\",\n",
    "    route_after_progress,\n",
    "    {\"save_contract\": \"save_contract\", \"generate_question\": \"generate_question\"},\n",
    ")\n",
    "workflow.add_edge(\"generate_question\", END)\n",
    "workflow.add_edge(\"save_contract\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5305202d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üìù Assistant Juridique Immobilier (Mode Notebook) ---\n",
      "Type 'quit' to exit.\n",
      "\n",
      "\n",
      "ü§ñ Assistant: Quel est le nom complet du bailleur ?\n",
      "\n",
      "ü§ñ Assistant: Quelle est l'adresse compl√®te du bailleur, s'il vous pla√Æt ?\n",
      "\n",
      "ü§ñ Assistant: Quel est le nom complet du locataire ?\n",
      "\n",
      "ü§ñ Assistant: Quel est le type de bien que vous souhaitez louer ? Est-ce un appartement ou une maison ?\n",
      "\n",
      "ü§ñ Assistant: Quelle est la surface en m√®tres carr√©s du logement que vous souhaitez louer ?\n",
      "\n",
      "ü§ñ Assistant: Le logement est-il meubl√© ? (Oui/Non)\n",
      "\n",
      "ü§ñ Assistant: Termin√© ! Le contrat a √©t√© sauvegard√© dans 'contrat_finalise.json'.\n",
      "\n",
      "‚úÖ Process Finished.\n"
     ]
    }
   ],
   "source": [
    "# 1. Define a Mock Template for the Contract\n",
    "initial_contract_template = {\n",
    "    \"bailleur\": {\n",
    "        \"nom_complet\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"},\n",
    "        \"adresse\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"}\n",
    "    },\n",
    "    \"locataire\": {\n",
    "        \"nom_complet\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"}\n",
    "    },\n",
    "    \"details_logement\": {\n",
    "        \"type_bien\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\", \"options\": [\"Appartement\", \"Maison\"]},\n",
    "        \"surface_m2\": {\"valeur\": None, \"requis\": True, \"type\": \"nombre\"},\n",
    "        \"meuble\": {\"valeur\": None, \"requis\": True, \"type\": \"booleen\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_interactive_session():\n",
    "    print(\"--- üìù Assistant Juridique Immobilier (Mode Notebook) ---\")\n",
    "    print(\"Type 'quit' to exit.\\n\")\n",
    "\n",
    "    # Initialize State\n",
    "    current_state = {\n",
    "        \"messages\": [],\n",
    "        \"contract_data\": initial_contract_template,\n",
    "        \"current_field_info\": None,\n",
    "        \"completed\": False\n",
    "    }\n",
    "\n",
    "    # Start the conversation loop\n",
    "    while True:\n",
    "        # Run the graph until it stops (at END)\n",
    "        # We pass the full current configuration to maintain state\n",
    "        events = app.invoke(current_state)\n",
    "        \n",
    "        # Update our local state variable with the result from the graph\n",
    "        current_state = events\n",
    "        \n",
    "        # Get the last message generated by the AI\n",
    "        last_message = current_state[\"messages\"][-1]\n",
    "        \n",
    "        # Print AI Response\n",
    "        print(f\"\\nü§ñ Assistant: {last_message.content}\")\n",
    "\n",
    "        # Check if we are done\n",
    "        if current_state.get(\"completed\", False):\n",
    "            print(\"\\n‚úÖ Process Finished.\")\n",
    "            break\n",
    "        \n",
    "        # Get User Input\n",
    "        user_input = input(\"\\nüë§ Vous: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            break\n",
    "            \n",
    "        # Append User Input to messages so the graph sees it next run\n",
    "        current_state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "\n",
    "# Run the interactive loop\n",
    "run_interactive_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "978f4682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Attempting to Draw Graph ---\n",
      "\n",
      "‚ùå Image generation failed. Error details:\n",
      "Failed to reach https://mermaid.ink API while trying to render your graph. Status code: 500.\n",
      "\n",
      "To resolve this issue:\n",
      "1. Check your internet connection and try again\n",
      "2. Try with higher retry settings: `draw_mermaid_png(..., max_retries=5, retry_delay=2.0)`\n",
      "3. Use the Pyppeteer rendering method which will render your graph locally in a browser: `draw_mermaid_png(..., draw_method=MermaidDrawMethod.PYPPETEER)`\n",
      "\n",
      "--- Fallback: ASCII Representation ---\n",
      "                   +-----------+                   \n",
      "                   | __start__ |                   \n",
      "                   +-----------+                   \n",
      "                 ...            ...                \n",
      "               ..                  ..              \n",
      "             ..                      ..            \n",
      "  +----------------+                   ..          \n",
      "  | process_answer |                 ..            \n",
      "  +----------------+               ..              \n",
      "                 ***            ...                \n",
      "                    **        ..                   \n",
      "                      **    ..                     \n",
      "              +--------------------+               \n",
      "              | determine_progress |               \n",
      "              +--------------------+               \n",
      "                 ...            ...                \n",
      "               ..                  ..              \n",
      "             ..                      ..            \n",
      "+-------------------+           +---------------+  \n",
      "| generate_question |           | save_contract |  \n",
      "+-------------------+           +---------------+  \n",
      "                 ***            ***                \n",
      "                    **        **                   \n",
      "                      **    **                     \n",
      "                    +---------+                    \n",
      "                    | __end__ |                    \n",
      "                    +---------+                    \n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "print(\"--- Attempting to Draw Graph ---\")\n",
    "\n",
    "try:\n",
    "    # This requires internet access (calls mermaid.ink API) and 'grandalf' for layout\n",
    "    display(Image(app.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ùå Image generation failed. Error details:\\n{e}\")\n",
    "    \n",
    "    print(\"\\n--- Fallback: ASCII Representation ---\")\n",
    "    try:\n",
    "        app.get_graph().print_ascii()\n",
    "    except Exception as e_ascii:\n",
    "        print(f\"Could not print ASCII either: {e_ascii}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295a665e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bail_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
