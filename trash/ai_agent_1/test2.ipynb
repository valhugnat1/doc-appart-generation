{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2efa6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import operator\n",
    "from typing import Annotated, Any, Dict, List, Optional, Union, TypedDict\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, BaseMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph, END\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Initialize LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d120aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_status(data: Dict) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Scans top-level keys. Returns the first category that has missing required fields.\n",
    "    Returns: {\n",
    "        \"category_key\": str, \n",
    "        \"missing_fields\": List[Dict]  # Contains key, type, path\n",
    "    }\n",
    "    Or None if everything is full.\n",
    "    \"\"\"\n",
    "    for category_key, content in data.items():\n",
    "        if not isinstance(content, dict):\n",
    "            continue\n",
    "            \n",
    "        missing_items = []\n",
    "        \n",
    "        # Helper to scan recursively within the category\n",
    "        def scan_recursive(sub_data, path):\n",
    "            for k, v in sub_data.items():\n",
    "                current_path = path + [k]\n",
    "                if isinstance(v, dict) and \"valeur\" in v and \"requis\" in v:\n",
    "                    # Check if empty\n",
    "                    if v[\"requis\"] and v[\"valeur\"] in [None, \"\", []]:\n",
    "                        missing_items.append({\n",
    "                            \"key\": k,\n",
    "                            \"path\": current_path,\n",
    "                            \"type\": v.get(\"type\"),\n",
    "                            \"options\": v.get(\"options\")\n",
    "                        })\n",
    "                elif isinstance(v, dict):\n",
    "                    scan_recursive(v, current_path)\n",
    "        \n",
    "        scan_recursive(content, [category_key])\n",
    "        \n",
    "        if missing_items:\n",
    "            return {\"category_key\": category_key, \"missing_fields\": missing_items}\n",
    "            \n",
    "    return None\n",
    "\n",
    "def update_json_value(data: Dict, path: List[str], new_value: Any):\n",
    "    \"\"\"Updates the JSON structure in-place.\"\"\"\n",
    "    ref = data\n",
    "    for key in path[:-1]:\n",
    "        ref = ref[key]\n",
    "    ref[path[-1]][\"valeur\"] = new_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a76b69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[List[BaseMessage], operator.add]\n",
    "    contract_data: Dict\n",
    "    current_category_info: Optional[Dict] # Info about the active category\n",
    "    validation_error: Optional[str]       # Message if previous input was incoherent\n",
    "    completed: bool\n",
    "\n",
    "# --- SCHEMA FOR EXTRACTION ---\n",
    "# This allows the LLM to return multiple updates + validation flags\n",
    "class FieldExtraction(BaseModel):\n",
    "    field_key: str = Field(description=\"The exact JSON key of the field being filled\")\n",
    "    value: Union[str, int, float, bool] = Field(description=\"The extracted value\")\n",
    "    is_coherent: bool = Field(description=\"True if the value makes logical sense. False if it seems wrong (e.g. negative rent).\")\n",
    "    correction_reason: Optional[str] = Field(description=\"If not coherent, explain why (e.g. 'Rent cannot be negative')\")\n",
    "\n",
    "class MultiFieldExtraction(BaseModel):\n",
    "    extractions: List[FieldExtraction]\n",
    "    general_comment: Optional[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87dab7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- NODE 1: SELECT NEXT GOAL ---\n",
    "def analyze_progress(state: AgentState):\n",
    "    data = state[\"contract_data\"]\n",
    "    status = get_category_status(data)\n",
    "    \n",
    "    if not status:\n",
    "        return {\"completed\": True, \"current_category_info\": None}\n",
    "    \n",
    "    return {\n",
    "        \"completed\": False, \n",
    "        \"current_category_info\": status,\n",
    "        # We keep validation_error if it exists from the previous turn, \n",
    "        # otherwise it clears naturally if we switch categories\n",
    "    }\n",
    "\n",
    "# --- NODE 2: GENERATE GROUPED QUESTION ---\n",
    "def generate_grouped_question(state: AgentState):\n",
    "    cat_info = state[\"current_category_info\"]\n",
    "    missing = cat_info[\"missing_fields\"]\n",
    "    error_msg = state.get(\"validation_error\")\n",
    "    \n",
    "    # Create a list of what is needed\n",
    "    needed_str = \"\\n\".join([f\"- {m['key']} (Type: {m['type']})\" for m in missing])\n",
    "    \n",
    "    category_name = cat_info[\"category_key\"]\n",
    "    \n",
    "    system_prompt = f\"\"\"\n",
    "    You are a real estate legal assistant. \n",
    "    Category currently being filled: '{category_name}'.\n",
    "    \n",
    "    MISSING FIELDS:\n",
    "    {needed_str}\n",
    "    \"\"\"\n",
    "    \n",
    "    if error_msg:\n",
    "        # If there was a mistake previously, prioritize asking for correction\n",
    "        system_prompt += f\"\\n\\n‚ö†Ô∏è CONTEXT - PREVIOUS ERROR: {error_msg}\\nAsk the user to clarify or correct the value.\"\n",
    "    else:\n",
    "        system_prompt += \"\\n\\nAsk the user for these details in a single, natural, polite message in French. Group the questions logically.\"\n",
    "\n",
    "    msg = llm.invoke([SystemMessage(content=system_prompt)])\n",
    "    return {\"messages\": [msg]}\n",
    "\n",
    "# --- NODE 3: PROCESS & VALIDATE INPUT ---\n",
    "def process_grouped_answer(state: AgentState):\n",
    "    last_msg = state[\"messages\"][-1]\n",
    "    cat_info = state[\"current_category_info\"]\n",
    "    \n",
    "    if not cat_info:\n",
    "        return {}\n",
    "\n",
    "    # Provide context of what we are looking for to the Extractor\n",
    "    missing_keys = [m[\"key\"] for m in cat_info[\"missing_fields\"]]\n",
    "    \n",
    "    extraction_prompt = f\"\"\"\n",
    "    The user replied: \"{last_msg.content}\"\n",
    "    \n",
    "    We are looking for values for these keys: {missing_keys} within the category '{cat_info['category_key']}'.\n",
    "    \n",
    "    1. Extract values for any keys mentioned.\n",
    "    2. VALIDATE: Check if the value makes sense (e.g., surface area > 0, valid email format).\n",
    "    3. If a value is incoherent, set is_coherent=False and explain why in correction_reason.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use the MultiFieldExtraction schema with function calling\n",
    "    structured_llm = llm.with_structured_output(MultiFieldExtraction, method=\"function_calling\")\n",
    "    result = structured_llm.invoke(extraction_prompt)\n",
    "    \n",
    "    current_data = state[\"contract_data\"]\n",
    "    new_validation_error = None\n",
    "    \n",
    "    # Process results\n",
    "    if result and result.extractions:\n",
    "        for item in result.extractions:\n",
    "            if item.is_coherent:\n",
    "                # Find the path for this key to update the JSON\n",
    "                # We look up the path in our missing_fields list\n",
    "                match = next((m for m in cat_info[\"missing_fields\"] if m[\"key\"] == item.field_key), None)\n",
    "                if match:\n",
    "                    update_json_value(current_data, match[\"path\"], item.value)\n",
    "            else:\n",
    "                # Logic for incoherence\n",
    "                new_validation_error = f\"User provided value '{item.value}' for '{item.field_key}' but it was flagged: {item.correction_reason}\"\n",
    "    \n",
    "    # If the LLM extracted nothing but the user spoke, we might need a fallback, \n",
    "    # but for this logic, we'll just loop back.\n",
    "    \n",
    "    return {\n",
    "        \"contract_data\": current_data,\n",
    "        \"validation_error\": new_validation_error\n",
    "    }\n",
    "\n",
    "def save_contract(state: AgentState):\n",
    "    with open(\"contrat_finalise.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(state[\"contract_data\"], f, ensure_ascii=False, indent=2)\n",
    "    return {\"messages\": [AIMessage(content=\"‚úÖ Formidable ! Toutes les sections sont compl√®tes. Le contrat est sauvegard√©.\")]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "edd07c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node(\"analyze_progress\", analyze_progress)\n",
    "workflow.add_node(\"generate_grouped_question\", generate_grouped_question)\n",
    "workflow.add_node(\"process_grouped_answer\", process_grouped_answer)\n",
    "workflow.add_node(\"save_contract\", save_contract)\n",
    "\n",
    "# --- EDGES ---\n",
    "\n",
    "def route_start(state: AgentState):\n",
    "    # If last message is human, process it\n",
    "    if state[\"messages\"] and isinstance(state[\"messages\"][-1], HumanMessage):\n",
    "        return \"process_grouped_answer\"\n",
    "    return \"analyze_progress\"\n",
    "\n",
    "def route_after_analysis(state: AgentState):\n",
    "    if state[\"completed\"]:\n",
    "        return \"save_contract\"\n",
    "    return \"generate_grouped_question\"\n",
    "\n",
    "workflow.set_conditional_entry_point(\n",
    "    route_start,\n",
    "    {\n",
    "        \"process_grouped_answer\": \"process_grouped_answer\", \n",
    "        \"analyze_progress\": \"analyze_progress\"\n",
    "    }\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"process_grouped_answer\", \"analyze_progress\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"analyze_progress\",\n",
    "    route_after_analysis,\n",
    "    {\n",
    "        \"save_contract\": \"save_contract\", \n",
    "        \"generate_grouped_question\": \"generate_grouped_question\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"generate_grouped_question\", END)\n",
    "workflow.add_edge(\"save_contract\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07ef4dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- üè¢ Assistant Intelligent (Mode Group√© & Validation) ---\n",
      "\n",
      "ü§ñ Assistant: Pour compl√©ter le dossier du propri√©taire, pourriez-vous s'il vous pla√Æt me fournir les informations suivantes : \n",
      "\n",
      "- Votre nom\n",
      "- Votre pr√©nom\n",
      "- La ville o√π vous r√©sidez\n",
      "\n",
      "Merci beaucoup pour votre coop√©ration !\n",
      "\n",
      "ü§ñ Assistant: Pour compl√©ter le dossier concernant le logement, pourriez-vous s'il vous pla√Æt me fournir quelques informations suppl√©mentaires ? J'aurais besoin de conna√Ætre l'adresse compl√®te du bien. De plus, pourriez-vous m'indiquer la surface en m√®tres carr√©s ainsi que le montant du loyer mensuel ? Merci beaucoup pour votre coop√©ration.\n",
      "\n",
      "ü§ñ Assistant: Pour compl√©ter le dossier concernant le logement, pourriez-vous s'il vous pla√Æt me fournir l'adresse compl√®te du bien immobilier ? Cela inclut le num√©ro, la rue, le code postal et la ville. Merci d'avance pour votre coop√©ration.\n",
      "\n",
      "ü§ñ Assistant: ‚úÖ Formidable ! Toutes les sections sont compl√®tes. Le contrat est sauvegard√©.\n"
     ]
    }
   ],
   "source": [
    "# Mock Template with Sections\n",
    "initial_contract_template = {\n",
    "    \"proprietaire\": {\n",
    "        \"nom\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"},\n",
    "        \"prenom\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"},\n",
    "        \"ville\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"}\n",
    "    },\n",
    "    \"logement\": {\n",
    "        \"adresse_bien\": {\"valeur\": None, \"requis\": True, \"type\": \"texte\"},\n",
    "        \"surface_m2\": {\"valeur\": None, \"requis\": True, \"type\": \"nombre\"},\n",
    "        \"loyer_mensuel\": {\"valeur\": None, \"requis\": True, \"type\": \"nombre\"}\n",
    "    }\n",
    "}\n",
    "\n",
    "def run_smart_session():\n",
    "    print(\"--- üè¢ Assistant Intelligent (Mode Group√© & Validation) ---\")\n",
    "    \n",
    "    current_state = {\n",
    "        \"messages\": [],\n",
    "        \"contract_data\": initial_contract_template,\n",
    "        \"current_category_info\": None,\n",
    "        \"validation_error\": None,\n",
    "        \"completed\": False\n",
    "    }\n",
    "\n",
    "    while True:\n",
    "        events = app.invoke(current_state)\n",
    "        current_state = events\n",
    "        \n",
    "        last_message = current_state[\"messages\"][-1]\n",
    "        print(f\"\\nü§ñ Assistant: {last_message.content}\")\n",
    "\n",
    "        if current_state.get(\"completed\", False):\n",
    "            break\n",
    "        \n",
    "        user_input = input(\"\\nüë§ Vous: \")\n",
    "        if user_input.lower() in [\"quit\", \"q\"]:\n",
    "            break\n",
    "            \n",
    "        current_state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "\n",
    "# Run it\n",
    "run_smart_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be59c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bail_generator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
